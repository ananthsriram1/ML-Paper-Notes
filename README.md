# Paper-Notes
A curated list and analysis of papers I've read, focusing on AI Systems, NLP, and MLOps.

| Paper Title & Link | How fun it was to read 1-10 | Key Area(s) | Core Contribution (1-Sentence) | My Takeaways | Date Read |

| Attention is All you Need | 7/10 | `Transformers`, `NLP`, `Attention`| Showed how the use of attention in every step of language processing can improve overall sentence analysis and translation capabilities - Kind of relatable in real life, focus on good things and it'll make me a bit happier!| [My Notes (https://docs.google.com/document/d/1Kpw9tBAar_Ep5GWx5YtOz1Ssa_sP0nesvAGTWgvEmHo/edit?usp=sharing)] | July 26, 2025 |


| BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | 7.5/10 | `NLP`, `Attention`, `Bidirectional Encoding`| BERT utilizes a bidirectional Transformer encoder and pre-training with masked language modeling and next sentence prediction to achieve state-of-the-art performance on various NLP tasks through fine-tuning.| https://docs.google.com/document/d/1CYjL35Xr8RfeHO28j1hg3nGJqgLjnEwyPqaaQDVzEtc/edit?tab=t.0#heading=h.771scb15louz | Aug 2, 2025 |

| No Questions are Stupid, but some are Poorly Posed: Understanding Poorly-Posed Information-Seeking Questions | 9/10 | `NLP`, | Good start to use AI to get a breadth, but to get a deeper understanding, turn to human-written papers| https://docs.google.com/document/d/1fOULQkmk1JONGF-v1WsPwRcR4mngsLivTpOPjYuZbBk/edit?tab=t.0 | Aug 3, 2025 |
